<div id="article_content" class="article_content clearfix">
       
<div class="para" style="font-size:14px;color:rgb(51,51,51);margin-bottom:15px;text-indent:28px;line-height:24px;background-color:rgb(255,255,255);">
 <span style="font-family:'Microsoft YaHei';">Scrapy是Python开发的一个快速、高层次的屏幕抓取和web抓取框架，用于抓取web站点并从页面中提取结构化的数据。Scrapy用途广泛，可以用于数据挖掘、监测和自动化测试，</span>
 <span style="font-family:'Microsoft YaHei';">Scrapy吸引人的地方在于它是一个框架，任何人都可以根据需求方便的修改。它也提供了多种类型爬虫的基类，如BaseSpider、sitemap爬虫等，最新版本又提供了web2.0爬虫的支持。</span>
</div>
<h2><a name="t0"></a>1.创建项目<br></h2>
<p>在开始爬取之前，您必须创建一个新的Scrapy项目。 进入您打算存储代码的目录中，运行下列命令:</p>
<pre><code class="language-python hljs">scrapy startproject day1</code><div class="hljs-button {2}" data-title="复制（为作者贡献原力分）" data-report-click="{&quot;spm&quot;:&quot;1001.2101.3001.4259&quot;}" onclick="hljs.copyCode(event)"></div></pre>
<p><img src="https://img-blog.csdn.net/20180601145315368?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTI1MzU2MDU=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt=""></p>
<p><img src="https://img-blog.csdn.net/20180601145411296?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTI1MzU2MDU=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt=""></p>
<p><img src="https://img-blog.csdn.net/20180601145451144?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTI1MzU2MDU=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt=""><br></p>
<h2><a name="t1"></a>2.定义item</h2>
<p>&nbsp;&nbsp;&nbsp;&nbsp;Item 是保存爬取到的数据的容器；其使用方法和<a href="https://so.csdn.net/so/search?from=pc_blog_highlight&amp;q=python" target="_blank" class="hl hl-1">python</a>字典类似， 并且提供了额外保护机制来避免拼写错误导致的未定义字段错误</p>
<pre><code class="language-python hljs"><ol class="hljs-ln" style="width:100%"><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="1"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">import</span> scrapy</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="2"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="3"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="4"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Day1Item</span>(scrapy.Item):</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="5"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    city = scrapy.Field()</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="6"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    temperature = scrapy.Field()</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="7"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    date = scrapy.Field() </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="8"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-keyword">pass</span></div></div></li></ol></code><div class="hljs-button {2}" data-title="复制（为作者贡献原力分）" data-report-click="{&quot;spm&quot;:&quot;1001.2101.3001.4259&quot;}" onclick="hljs.copyCode(event)"></div></pre>
<h3><a name="t2"></a>3.编写爬虫</h3>
<p>Spider是用户编写用于从单个网站(或者一些网站)爬取数据的类。其包含了一个用于下载的初始URL，如何跟进网页中的链接以及如何分析页面中的内容， 提取生成 item 的方法。</p>
<p><img src="https://img-blog.csdn.net/20180601145826688?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTI1MzU2MDU=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt=""><br></p>
<p>在spiders中创建一个名为sinaweather.py文件</p>
<pre><code class="language-python hljs"><ol class="hljs-ln" style="width:782px"><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="1"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">import</span> scrapy</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="2"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">from</span> day1.items <span class="hljs-keyword">import</span> Day1Item&nbsp; &nbsp; <span class="hljs-comment"># day1是文件夹的名，Day1Item是items.py中的类class名</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="3"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">class</span> <span class="hljs-title class_">weatherSpider</span>(scrapy.spiders.Spider):&nbsp; &nbsp;<span class="hljs-comment">#weatherSpider是自定义的名</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="4"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">&nbsp; &nbsp; name = <span class="hljs-string">"sina"</span>&nbsp; &nbsp; &nbsp; &nbsp;<span class="hljs-comment">#sina是自定义的名</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="5"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">&nbsp; &nbsp; allowed_domains = [<span class="hljs-string">'sina.com.cn'</span>]&nbsp; &nbsp;<span class="hljs-comment">#sina.com.cn是限定在这个网站的范围之内爬虫</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="6"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">&nbsp; &nbsp; start_urls = [<span class="hljs-string">'http://weather.sina.com.cn/xian'</span>]&nbsp; <span class="hljs-comment">#开始爬虫的网址</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="7"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">&nbsp; &nbsp; <span class="hljs-keyword">def</span> <span class="hljs-title function_">parse</span>(<span class="hljs-params">self, response</span>):</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="8"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">&nbsp; &nbsp; &nbsp; &nbsp; item= Day1Item()</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="9"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">&nbsp; &nbsp; &nbsp; &nbsp; item[<span class="hljs-string">'city'</span>] = response.xpath(<span class="hljs-string">'//*[@class="slider_ct_name"]/text()'</span>).extract()</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="10"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">&nbsp; &nbsp; &nbsp; &nbsp; item[<span class="hljs-string">'temperature'</span>]=response.xpath(<span class="hljs-string">'//*[@class="wt_fc_c0_i_temp"]/text()'</span>).extract()</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="11"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">&nbsp; &nbsp; &nbsp; &nbsp; item[<span class="hljs-string">'date'</span>]=response.xpath(<span class="hljs-string">'//*[@class="wt_fc_c0_i_date"]/text()'</span>).extract()</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="12"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">&nbsp; &nbsp; &nbsp; &nbsp; <span class="hljs-keyword">return</span> item</div></div></li></ol></code><div class="hljs-button {2}" data-title="复制（为作者贡献原力分）" data-report-click="{&quot;spm&quot;:&quot;1001.2101.3001.4259&quot;}" onclick="hljs.copyCode(event)"></div></pre>
<h2><a name="t3"></a>4.修改配置文件（settings）</h2>
<pre><code class="language-python hljs"><ol class="hljs-ln" style="width:100%"><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="1"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">BOT_NAME = <span class="hljs-string">'day1'</span>  </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="2"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="3"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">SPIDER_MODULES = [<span class="hljs-string">'day1.spiders'</span>]</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="4"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">NEWSPIDER_MODULE = <span class="hljs-string">'day1.spiders'</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="5"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="6"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">FEED_EXPORT_ENCODING = <span class="hljs-string">'utf-8'</span>     </div></div></li></ol></code><div class="hljs-button {2}" data-title="复制（为作者贡献原力分）" data-report-click="{&quot;spm&quot;:&quot;1001.2101.3001.4259&quot;}" onclick="hljs.copyCode(event)"></div></pre>
<h2><a name="t4"></a>5.执行爬虫命令</h2>
<p><span style="font-family:'Microsoft YaHei';">在命令行输入如下命令：</span></p>
<pre><code class="language-python hljs">scrapy crawl sina -o test.json</code><div class="hljs-button {2}" data-title="复制（为作者贡献原力分）" data-report-click="{&quot;spm&quot;:&quot;1001.2101.3001.4259&quot;}" onclick="hljs.copyCode(event)"></div></pre>
<p>我们看到命令行出现如下内容，说明爬虫成功了</p>
<p><img src="https://img-blog.csdn.net/20180601151300487?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTI1MzU2MDU=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt=""></p>
<p>然后我们回到根目录下，看我们刚保存的test.json文件，我们看到如下json内容，说明需要爬到的数据被保存到test.json文件中</p>
<p><img src="https://img-blog.csdn.net/20180601151444413?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTI1MzU2MDU=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt=""><br></p>
<p>至此第一个scrapy爬虫示例基本实现，后续会更深入的学习如何利用scrapy抓取数据</p>
                </div><div><div></div></div>
        </div>